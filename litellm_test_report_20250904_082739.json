{
  "start_time": "2025-09-04T08:27:21.657746",
  "end_time": "2025-09-04T08:27:39.829977",
  "total_duration": 18.172231,
  "total_tests": 3,
  "successful_tests": 3,
  "failed_tests": 0,
  "success_rate": 100.0,
  "test_results": [
    {
      "name": "å¿«é€ŸéªŒè¯æµ‹è¯•",
      "script": "quick_litellm_test.py",
      "success": true,
      "duration": 3.688779830932617,
      "return_code": 0,
      "stdout": "LiteLLM å¿«é€ŸéªŒè¯å¼€å§‹...\n==================================================\nâœ… LiteLLM å·²å®‰è£…\n\nå¯¼å…¥æµ‹è¯•:\nğŸ”„ æµ‹è¯• LiteLLM å¯¼å…¥...\nâœ… LiteLLM å¯¼å…¥æˆåŠŸ\n   ç‰ˆæœ¬: Unknown\n\nåŸºæœ¬è®¾ç½®:\nğŸ”„ æµ‹è¯•åŸºæœ¬è®¾ç½®...\nâœ… åŸºæœ¬è®¾ç½®æˆåŠŸ\n\næ¨¡å‹æ ¼å¼:\nğŸ”„ æµ‹è¯•æ¨¡å‹æ ¼å¼...\n   æ”¯æŒæ ¼å¼: openai/gpt-3.5-turbo\n   æ”¯æŒæ ¼å¼: openai/gpt-4\n   æ”¯æŒæ ¼å¼: anthropic/claude-3-sonnet-20240229\n   æ”¯æŒæ ¼å¼: google/gemini-pro\nâœ… æ¨¡å‹æ ¼å¼æµ‹è¯•å®Œæˆ\n\næ¨¡æ‹Ÿè°ƒç”¨:\nğŸ”„ æµ‹è¯•æ¨¡æ‹Ÿè°ƒç”¨...\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nâœ… è°ƒç”¨å¤±è´¥ï¼ˆé¢„æœŸï¼‰- æ¥å£æ­£å¸¸\n   é”™è¯¯ç±»å‹: AuthenticationError\n\nå¼‚å¸¸å¤„ç†:\nğŸ”„ æµ‹è¯•å¼‚å¸¸å¤„ç†...\nâš ï¸  OpenAI åº“æœªå®‰è£…ï¼Œè·³è¿‡å¼‚å¸¸æ˜ å°„æµ‹è¯•\n\né¡¹ç›®ç»“æ„:\nğŸ”„ æ£€æŸ¥å½“å‰é¡¹ç›®ç»“æ„...\n   âœ… config.py\n   âœ… services/openai_service.py\n   âœ… services/__init__.py\nâœ… é¡¹ç›®ç»“æ„æ£€æŸ¥å®Œæˆ\n\n==================================================\nå¿«é€ŸéªŒè¯æ€»ç»“\n==================================================\né€šè¿‡: 6/6\næˆåŠŸç‡: 100.0%\n\nğŸ‰ LiteLLM å¿«é€ŸéªŒè¯ï¼šå®Œå…¨æˆåŠŸ\n   å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥æµ‹è¯•\n\n==================================================\nä¸‹ä¸€æ­¥å»ºè®®\n==================================================\n  1. è¿è¡Œå®Œæ•´æµ‹è¯•: python test_litellm_feasibility.py\n  2. è¿è¡Œå®ç°æµ‹è¯•: python test_litellm_implementation.py\n  3. æŸ¥çœ‹è¯„ä¼°æŠ¥å‘Š: cat litellm_evaluation.md\n  4. æŸ¥çœ‹å®ç°æ–¹æ¡ˆ: cat migration_implementation.md\n  5. å¼€å§‹åˆ›å»ºç»Ÿä¸€ AI æœåŠ¡\n\né…ç½®å»ºè®®:\n  â€¢ è®¾ç½®çœŸå®çš„ API å¯†é’¥è¿›è¡Œå®Œæ•´æµ‹è¯•\n  â€¢ è€ƒè™‘å¤šæä¾›å•†é…ç½®\n  â€¢ å‡†å¤‡å›é€€æ–¹æ¡ˆ\n",
      "stderr": "",
      "timestamp": "2025-09-04T08:27:25.346602"
    },
    {
      "name": "å¯è¡Œæ€§è¯„ä¼°æµ‹è¯•",
      "script": "test_litellm_feasibility.py",
      "success": true,
      "duration": 3.528742790222168,
      "return_code": 0,
      "stdout": "LiteLLM å¯è¡Œæ€§æµ‹è¯•å¼€å§‹...\næµ‹è¯•ç›®æ ‡ï¼šéªŒè¯ LiteLLM åœ¨ Anki AI Chat Tool é¡¹ç›®ä¸­çš„é€‚ç”¨æ€§\n============================================================\n1. LiteLLM å®‰è£…å’Œå¯¼å…¥æµ‹è¯•\n============================================================\nâœ… LiteLLM å¯¼å…¥æˆåŠŸ\n   ç‰ˆæœ¬: Unknown\nâœ… completion å‡½æ•°å¯¼å…¥æˆåŠŸ\n\n============================================================\n2. OpenAI å…¼å®¹æ€§æµ‹è¯•\n============================================================\nâœ… OpenAI å¼‚å¸¸ç±»å‹å¯¼å…¥æˆåŠŸ (æ–°ç‰ˆæœ¬)\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nâœ… LiteLLM å¼‚å¸¸æ­£ç¡®æ˜ å°„åˆ° OpenAI å¼‚å¸¸\n   å¼‚å¸¸ç±»å‹: AuthenticationError\n\n============================================================\n3. å“åº”æ ¼å¼å…¼å®¹æ€§æµ‹è¯•\n============================================================\nâœ… æµ‹è¯•å“åº”æ ¼å¼ç»“æ„...\nâœ… å“åº”æ ¼å¼ç¬¦åˆ OpenAI æ ‡å‡†\n   åŒ…å«å­—æ®µ: id, created, model, object, choices, usage\n   choices[0].message.content è·¯å¾„å¯ç”¨\n\n============================================================\n4. å½“å‰é¡¹ç›®é›†æˆå…¼å®¹æ€§æµ‹è¯•\n============================================================\nâœ… å½“å‰é…ç½®ç³»ç»Ÿå¯ç”¨\n   API å¯†é’¥è®¾ç½®: å¦\n   æ¨¡å‹: gpt-3.5-turbo\nâœ… ç°æœ‰ OpenAI æœåŠ¡å¯å¯¼å…¥\n   âœ… æ–¹æ³• get_response å­˜åœ¨\n   âœ… æ–¹æ³• validate_api_key å­˜åœ¨\n   âœ… æ–¹æ³• get_service_status å­˜åœ¨\n   âœ… æ–¹æ³• update_config å­˜åœ¨\n\n============================================================\n5. LiteLLM åŸºæœ¬åŠŸèƒ½æµ‹è¯•\n============================================================\nâœ… æµ‹è¯•é…ç½®è®¾ç½®...\n   å…¨å±€é…ç½®è®¾ç½®æˆåŠŸ\nâœ… æµ‹è¯•ç¯å¢ƒå˜é‡è®¾ç½®...\n   OPENAI_API_KEY è®¾ç½®æˆåŠŸ\n   ANTHROPIC_API_KEY è®¾ç½®æˆåŠŸ\n   GOOGLE_API_KEY è®¾ç½®æˆåŠŸ\nâœ… æµ‹è¯•æ¨¡å‹åç§°æ ¼å¼...\n   æ”¯æŒæ¨¡å‹æ ¼å¼: openai/gpt-3.5-turbo\n   æ”¯æŒæ¨¡å‹æ ¼å¼: openai/gpt-4\n   æ”¯æŒæ¨¡å‹æ ¼å¼: anthropic/claude-3-sonnet\n   æ”¯æŒæ¨¡å‹æ ¼å¼: google/gemini-pro\n\n============================================================\n6. é€‚é…å™¨æ¨¡å¼å¯è¡Œæ€§æµ‹è¯•\n============================================================\nâœ… é€‚é…å™¨ç±»åˆ›å»ºæˆåŠŸ\nâœ… get_response æ–¹æ³•: æ¨¡æ‹Ÿ AI å“åº”\nâœ… validate_api_key æ–¹æ³•: True, API key is valid\nâœ… get_service_status æ–¹æ³•: 5 ä¸ªçŠ¶æ€å­—æ®µ\nâœ… update_config æ–¹æ³•æ‰§è¡ŒæˆåŠŸ\n\n============================================================\n7. è¿ç§»ç­–ç•¥å¯è¡Œæ€§æµ‹è¯•\n============================================================\nâœ… æ¸è¿›å¼è¿ç§»ç­–ç•¥æµ‹è¯•...\n   é˜¶æ®µ 1: ä¿æŒç°æœ‰æ¥å£ - å¯è¡Œ\n   é˜¶æ®µ 2: åº•å±‚æ›¿æ¢ä¸º LiteLLM - å¯è¡Œ\n   é˜¶æ®µ 3: æ·»åŠ å¤šæä¾›å•†æ”¯æŒ - å¯è¡Œ\n   é˜¶æ®µ 4: å¯ç”¨é«˜çº§åŠŸèƒ½ - å¯è¡Œ\nâœ… å›é€€æœºåˆ¶æµ‹è¯•...\n   å¯ä»¥ä¿æŒåŸæœ‰ OpenAI æœåŠ¡ä½œä¸ºå¤‡é€‰\n   å¯ä»¥é€šè¿‡é…ç½®å¼€å…³åˆ‡æ¢å®ç°\n\n============================================================\n8. å®æ–½å»ºè®®\n============================================================\n\nImmediate Actions:\n  â€¢ å®‰è£… LiteLLM: pip install litellm\n  â€¢ åˆ›å»º services/unified_ai_service.py\n  â€¢ æ‰©å±• config.py æ”¯æŒå¤šæä¾›å•†\n  â€¢ åˆ›å»ºé€‚é…å™¨ä¿æŒå‘åå…¼å®¹\n\nConfiguration Changes:\n  â€¢ æ·»åŠ  ai_provider é…ç½®é¡¹\n  â€¢ æ·»åŠ å¤šæä¾›å•† API å¯†é’¥é…ç½®\n  â€¢ æ·»åŠ é‡è¯•å’Œè¶…æ—¶é…ç½®\n  â€¢ ä¿æŒç°æœ‰é…ç½®å‘åå…¼å®¹\n\nTesting Strategy:\n  â€¢ åˆ›å»º LiteLLM åŠŸèƒ½æµ‹è¯•\n  â€¢ éªŒè¯å¤šæä¾›å•†åˆ‡æ¢\n  â€¢ æµ‹è¯•é”™è¯¯å¤„ç†å’Œé‡è¯•\n  â€¢ æ€§èƒ½åŸºå‡†æµ‹è¯•\n\nRollback Plan:\n  â€¢ ä¿æŒåŸæœ‰ openai_service.py\n  â€¢ æ·»åŠ  use_legacy_service é…ç½®å¼€å…³\n  â€¢ æä¾›å¿«é€Ÿå›é€€æœºåˆ¶\n\n============================================================\næµ‹è¯•ç»“æœæ€»ç»“\n============================================================\né€šè¿‡æµ‹è¯•: 7/7\næˆåŠŸç‡: 100.0%\n\nğŸ‰ LiteLLM è¿ç§»å¯è¡Œæ€§è¯„ä¼°ï¼šå¼ºçƒˆæ¨è\n   â€¢ å…¼å®¹æ€§è‰¯å¥½\n   â€¢ é£é™©å¯æ§\n   â€¢ æ”¶ç›Šæ˜æ˜¾\n",
      "stderr": "",
      "timestamp": "2025-09-04T08:27:28.875467"
    },
    {
      "name": "å®ç°åŠŸèƒ½æµ‹è¯•",
      "script": "test_litellm_implementation.py",
      "success": true,
      "duration": 10.95436406135559,
      "return_code": 0,
      "stdout": "LiteLLM å®ç°æµ‹è¯•å¼€å§‹...\næµ‹è¯•ç›®æ ‡ï¼šéªŒè¯ LiteLLM çš„å®é™…åŠŸèƒ½å’Œé›†æˆæ•ˆæœ\nâœ… LiteLLM ç‰ˆæœ¬: Unknown\n============================================================\n1. åŸºæœ¬åŠŸèƒ½æµ‹è¯•\n============================================================\nâœ… LiteLLM é…ç½®è®¾ç½®æˆåŠŸ\næœåŠ¡çŠ¶æ€:\n  ai_provider: openai\n  model: openai/gpt-3.5-turbo\n  api_key_set: False\n  max_tokens: 500\n  temperature: 0.7\n  retry_attempts: 3\n  available_providers: []\n\n============================================================\n2. å¯¹è¯æ¨¡æ‹Ÿæµ‹è¯•\n============================================================\nâœ… LiteLLM é…ç½®è®¾ç½®æˆåŠŸ\nğŸ”„ å‘é€å¯¹è¯è¯·æ±‚...\nğŸ”„ ä½¿ç”¨æ¨¡å‹: openai/gpt-3.5-turbo\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nâš ï¸  æ¨¡æ‹Ÿå“åº”: AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: litellm.AuthenticationError: AuthenticationError: OpenAIException - Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.\n   (è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯æµ‹è¯• API å¯†é’¥)\n\n============================================================\n3. é”™è¯¯å¤„ç†æµ‹è¯•\n============================================================\nâœ… LiteLLM é…ç½®è®¾ç½®æˆåŠŸ\nğŸ”„ æµ‹è¯•ç©ºå¯¹è¯å†å²...\n   ç»“æœ: AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: Empty conversation history\nğŸ”„ æµ‹è¯•æ— æ•ˆ API å¯†é’¥...\nğŸ”„ ä½¿ç”¨æ¨¡å‹: openai/gpt-3.5-turbo\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'temperature': 0.7, 'max_tokens': 500, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: invalid-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\n   ç»“æœ: AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: litellm.AuthenticationError: Authentica...\n\n============================================================\n4. æä¾›å•†åˆ‡æ¢æµ‹è¯•\n============================================================\nâœ… LiteLLM é…ç½®è®¾ç½®æˆåŠŸ\nğŸ”„ æµ‹è¯•æä¾›å•†: openai\n   æ¨¡å‹: openai/gpt-3.5-turbo\n   API å¯†é’¥: æ— \n   ä»…æ¨¡æ‹Ÿæµ‹è¯•\nğŸ”„ æµ‹è¯•æä¾›å•†: anthropic\n   æ¨¡å‹: anthropic/claude-3-sonnet-20240229\n   API å¯†é’¥: æ— \n   ä»…æ¨¡æ‹Ÿæµ‹è¯•\nğŸ”„ æµ‹è¯•æä¾›å•†: google\n   æ¨¡å‹: google/gemini-pro\n   API å¯†é’¥: æ— \n   ä»…æ¨¡æ‹Ÿæµ‹è¯•\n\n============================================================\n5. å‘åå…¼å®¹æ€§æµ‹è¯•\n============================================================\nâœ… LiteLLM é…ç½®è®¾ç½®æˆåŠŸ\nâœ… é€‚é…å™¨åˆ›å»ºæˆåŠŸ\nâœ… get_service_status: 5 ä¸ªå­—æ®µ\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'max_tokens': 10, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'max_tokens': 10, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'max_tokens': 10, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nSYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\nFinal returned optional params: {'max_tokens': 10, 'max_retries': 0, 'extra_body': {}}\nopenai.py: Received openai error - Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\nRAW RESPONSE:\nError code: 401 - {'error': {'message': 'Incorrect API key provided: sk-test-key. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n\n\n\n\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\nLiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n\nâœ… validate_api_key: False\nâœ… update_config æ‰§è¡ŒæˆåŠŸ\n\n============================================================\nå®ç°æµ‹è¯•æ€»ç»“\n============================================================\né€šè¿‡æµ‹è¯•: 5/5\næˆåŠŸç‡: 100.0%\n\nğŸ‰ LiteLLM å®ç°æµ‹è¯•ï¼šå®Œå…¨æˆåŠŸ\n   å¯ä»¥å¼€å§‹æ­£å¼è¿ç§»\n",
      "stderr": "\u001b[92m08:27:30 - LiteLLM:WARNING\u001b[0m: utils.py:528 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n\u001b[92m08:27:34 - LiteLLM:WARNING\u001b[0m: utils.py:528 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n\u001b[92m08:27:37 - LiteLLM:WARNING\u001b[0m: utils.py:528 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n",
      "timestamp": "2025-09-04T08:27:39.829904"
    }
  ]
}